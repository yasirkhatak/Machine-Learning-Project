{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   V_in          60000 non-null  float64\n",
      " 1   Measured_RPM  60000 non-null  float64\n",
      " 2   Vibration_1   60000 non-null  float64\n",
      " 3   Vibration_2   60000 non-null  float64\n",
      " 4   Vibration_3   60000 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 2.3 MB\n",
      "None\n",
      "               V_in  Measured_RPM   Vibration_1   Vibration_2   Vibration_3\n",
      "count  60000.000000  6.000000e+04  60000.000000  60000.000000  60000.000000\n",
      "mean       1.590400 -1.638350e+07      0.602460      0.915983      0.673900\n",
      "std        0.807118  6.052935e+07      1.189392      1.583087      1.239735\n",
      "min        0.000000 -2.400000e+08      0.000000      0.000000      0.000000\n",
      "25%        2.000000  6.131318e+02      0.027322      0.044179      0.033920\n",
      "50%        2.000000  6.152253e+02      0.107946      0.190694      0.131169\n",
      "75%        2.000000  6.403006e+02      0.566104      0.998927      0.690722\n",
      "max        2.000000  6.431334e+02      7.861973      8.807942      7.842145\n",
      "V_in            0\n",
      "Measured_RPM    0\n",
      "Vibration_1     0\n",
      "Vibration_2     0\n",
      "Vibration_3     0\n",
      "dtype: int64\n",
      "V_in            0\n",
      "Measured_RPM    0\n",
      "Vibration_1     0\n",
      "Vibration_2     0\n",
      "Vibration_3     0\n",
      "dtype: int64\n",
      "V_in            0\n",
      "Measured_RPM    0\n",
      "Vibration_1     0\n",
      "Vibration_2     0\n",
      "Vibration_3     0\n",
      "dtype: int64\n",
      "V_in            0\n",
      "Measured_RPM    0\n",
      "Vibration_1     0\n",
      "Vibration_2     0\n",
      "Vibration_3     0\n",
      "dtype: int64\n",
      "V_in            0\n",
      "Measured_RPM    0\n",
      "Vibration_1     0\n",
      "Vibration_2     0\n",
      "Vibration_3     0\n",
      "dtype: int64\n",
      "(240000, 4)\n",
      "(240000, 4, 1)\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 33s 5ms/step - loss: 1.1799 - accuracy: 0.4573 - val_loss: 0.9862 - val_accuracy: 0.5144\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 20s 3ms/step - loss: 0.9051 - accuracy: 0.5468 - val_loss: 0.8352 - val_accuracy: 0.6138\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.7683 - accuracy: 0.6091 - val_loss: 0.7192 - val_accuracy: 0.6065\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.6781 - accuracy: 0.6501 - val_loss: 0.6297 - val_accuracy: 0.6644\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.6210 - accuracy: 0.6794 - val_loss: 0.5788 - val_accuracy: 0.6954\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 20s 3ms/step - loss: 0.5800 - accuracy: 0.6998 - val_loss: 0.5475 - val_accuracy: 0.7005\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 21s 4ms/step - loss: 0.5549 - accuracy: 0.7090 - val_loss: 0.5516 - val_accuracy: 0.7421\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 22s 4ms/step - loss: 0.5344 - accuracy: 0.7172 - val_loss: 0.5102 - val_accuracy: 0.7511\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.5196 - accuracy: 0.7219 - val_loss: 0.5104 - val_accuracy: 0.7606\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 19s 3ms/step - loss: 0.5092 - accuracy: 0.7263 - val_loss: 0.4910 - val_accuracy: 0.7129\n",
      "(60000, 4, 1)\n",
      "4941      1\n",
      "51775     4\n",
      "115253    3\n",
      "299321    0\n",
      "173570    4\n",
      "         ..\n",
      "75094     3\n",
      "171847    3\n",
      "138313    3\n",
      "271268    4\n",
      "72612     3\n",
      "Name: unbalance, Length: 60000, dtype: int64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 199\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39m# Calculate metrics\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error, mean_absolute_error, r2_score\n\u001b[1;32m--> 199\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y_test, y_pred)\n\u001b[0;32m    200\u001b[0m mae \u001b[39m=\u001b[39m mean_absolute_error(y_test, y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "df0=pd.read_csv('0D.csv',nrows=60000)\n",
    "df1=pd.read_csv('1D.csv',nrows=60000)\n",
    "df2=pd.read_csv('2D.csv',nrows=60000)\n",
    "df3=pd.read_csv('3D.csv',nrows=60000)\n",
    "df4=pd.read_csv('4D.csv',nrows=60000)\n",
    "df0.dropna(inplace=True)\n",
    "df0.fillna(value=0, inplace=True)\n",
    "df0.fillna(df0.mean(), inplace=True)\n",
    "\n",
    "\n",
    "df1.dropna(inplace=True)\n",
    "df1.fillna(value=0, inplace=True)\n",
    "df1.fillna(df2.mean(), inplace=True)\n",
    "\n",
    "\n",
    "df2.dropna(inplace=True)\n",
    "df2.fillna(value=0, inplace=True)\n",
    "df2.fillna(df2.mean(), inplace=True)\n",
    "\n",
    "\n",
    "df3.dropna(inplace=True)\n",
    "df3.fillna(value=0, inplace=True)\n",
    "df3.fillna(df3.mean(), inplace=True)\n",
    "\n",
    "\n",
    "df4.dropna(inplace=True)\n",
    "df4.fillna(value=0, inplace=True)\n",
    "df4.fillna(df4.mean(), inplace=True)\n",
    "print(df1.info())\n",
    "print(df1.describe())\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df0)\n",
    "normalized_df0= pd.DataFrame(normalized_data, columns=df0.columns)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df1)\n",
    "normalized_df1= pd.DataFrame(normalized_data, columns=df1.columns)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df2)\n",
    "normalized_df2= pd.DataFrame(normalized_data, columns=df2.columns)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df3)\n",
    "normalized_df3= pd.DataFrame(normalized_data, columns=df3.columns)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df4)\n",
    "normalized_df4= pd.DataFrame(normalized_data, columns=df4.columns)\n",
    "import pandas as pd\n",
    "\n",
    "normalized_df0['unbalance'] = 0\n",
    "length = len(normalized_df0)\n",
    "while len(normalized_df0['unbalance']) < length:\n",
    "    normalized_df0['unbalance'].loc[len(normalized_df0['unbalance'])] = 0\n",
    "    \n",
    "    \n",
    "normalized_df1['unbalance'] = 1\n",
    "length = len(normalized_df1)\n",
    "while len(normalized_df1['unbalance']) < length:\n",
    "    normalized_df1['unbalance'].loc[len(normalized_df1['unbalance'])] = 1\n",
    "\n",
    "normalized_df2['unbalance'] = 2\n",
    "length = len(normalized_df2)\n",
    "while len(normalized_df2['unbalance']) < length:\n",
    "    normalized_df2['unbalance'].loc[len(normalized_df2['unbalance'])] = 2\n",
    "    \n",
    "normalized_df3['unbalance'] = 3\n",
    "length = len(normalized_df3)\n",
    "while len(normalized_df3['unbalance']) < length:\n",
    "    normalized_df3['unbalance'].loc[len(normalized_df3['unbalance'])] = 3\n",
    "    \n",
    "normalized_df4['unbalance'] = 4\n",
    "length = len(normalized_df4)\n",
    "while len(normalized_df4['unbalance']) < length:\n",
    "    normalized_df4['unbalance'].loc[len(normalized_df4['unbalance'])] = 4\n",
    "print(df0.isnull().sum())\n",
    "print(df1.isnull().sum())\n",
    "print(df2.isnull().sum())\n",
    "print(df3.isnull().sum())\n",
    "print(df4.isnull().sum())\n",
    "dfs = [normalized_df0, normalized_df1, normalized_df3, normalized_df3, normalized_df4]\n",
    "\n",
    "result = pd.concat(dfs, axis=0)\n",
    "result = result.reset_index(drop=True)\n",
    "shuffled_result = result.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_result.head(100)\n",
    "X = shuffled_result.drop('unbalance', axis=1)\n",
    "y = shuffled_result['unbalance']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming you have a DataFrame named 'result'\n",
    "\n",
    "# # Create a figure and a grid of subplots\n",
    "# fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "# # Plot histogram of 'V_in' in the first subplot\n",
    "# axs[0, 0].hist(result['V_in'], bins=10)\n",
    "# axs[0, 0].set_xlabel('V_in')\n",
    "# axs[0, 0].set_ylabel('Frequency')\n",
    "# axs[0, 0].set_title('Histogram of V_in')\n",
    "\n",
    "# # Plot histogram of 'Measured_RPM' in the second subplot\n",
    "# axs[0, 1].hist(result['Measured_RPM'], bins=10)\n",
    "# axs[0, 1].set_xlabel('Measured_RPM')\n",
    "# axs[0, 1].set_ylabel('Frequency')\n",
    "# axs[0, 1].set_title('Histogram of Measured_RPM')\n",
    "\n",
    "# # Plot histogram of 'Vibration_1' in the third subplot\n",
    "# axs[0, 2].hist(result['Vibration_1'], bins=10)\n",
    "# axs[0, 2].set_xlabel('Vibration_1')\n",
    "# axs[0, 2].set_ylabel('Frequency')\n",
    "# axs[0, 2].set_title('Histogram of Vibration_1')\n",
    "\n",
    "# # Plot histogram of 'Vibration_2' in the fourth subplot\n",
    "# axs[1, 0].hist(result['Vibration_2'], bins=10)\n",
    "# axs[1, 0].set_xlabel('Vibration_2')\n",
    "# axs[1, 0].set_ylabel('Frequency')\n",
    "# axs[1, 0].set_title('Histogram of Vibration_2')\n",
    "\n",
    "# # Plot histogram of 'Vibration_3' in the fifth subplot\n",
    "# axs[1, 1].hist(result['Vibration_3'], bins=10)\n",
    "# axs[1, 1].set_xlabel('Vibration_3')\n",
    "# axs[1, 1].set_ylabel('Frequency')\n",
    "# axs[1, 1].set_title('Histogram of Vibration_3')\n",
    "\n",
    "# # Hide the sixth subplot (if not needed)\n",
    "# axs[1, 2].axis('off')\n",
    "\n",
    "# # Adjust the spacing between subplots\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "feature_Sel=SelectFromModel(Lasso(alpha=0.005,random_state=0))\n",
    "feature_Sel.fit(X_train,y_train)\n",
    "feature_Sel.get_support()\n",
    "selected_feat=X_train.columns[(feature_Sel.get_support())]\n",
    "X_train=X_train[selected_feat]\n",
    "X_test=X_test[selected_feat]\n",
    "print(X_train.shape)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "# Determine the number of classes\n",
    "num_classes = y_train.shape[1]\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history=model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "#loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(X_test.shape)\n",
    "print(y_test)\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
